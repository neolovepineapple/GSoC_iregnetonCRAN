---
title: "Hard_Test"
author: "Ao Ni"
date: "2019/3/14"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Hello everyone, this is Ao Ni, a senior student major in Statistics who will pursue a master degree in Computer science in the near future.Here is my solution for Hard Test.


```{r cars, message=FALSE, warning=FALSE}
library(iregnet)
library(glmnet)
library(lasso2)
library(ggplot2)
library(penaltyLearning)
library(rmarkdown)
library(caret)
library(microbenchmark)
data("Prostate")
data('neuroblastomaProcessed')
```


Let's start at a test error metrics function.
```{r, echo=FALSE}
test_error <- function(predict, label){
  len <- length(predict)
  errors <- 0
  for (i in array(1:len)){
    if ((label[i,1]<=predict[i]) && (label[i,2]>=predict[i])){
      
    }else{
      errors <- errors+1
    }
  }
  return(errors/len)
}
```

Then we can run a IntervalRegressionCV and test its precision.

```{r, echo=FALSE}
#prepare the data
X <- neuroblastomaProcessed$feature.mat
Y.iter <- neuroblastomaProcessed$target.mat
select.col <- apply(X,2,function(x){
  return(max(x)-min(x)!=0)
})
X = X[,select.col]
Y.ireg = Y.iter
Y.ireg[abs(Y.ireg) == Inf] = NA
```

```{r, error=FALSE, warning= FALSE}
set.seed(10)
fit.iter <- IntervalRegressionCV(X,Y.iter, n.folds = 5L)
perd.iter <- fit.iter$predict()
error_rate.iter <- test_error(perd.iter, Y.iter)
cat("The error rate for IntervalRegressionCV:",error_rate.iter)
```

The error rate is ! Look at our iregnet function. First we start at a customized function to perform cross validation.


```{r,error=FALSE, warning= FALSE}
iregnet.CV<- function(x, y, n.folds = 5L, seed = 10){
  set.seed(seed)
  idx <- array(1:nrow(x))
  pred.val <- array(0,nrow(x))
  fld <- createFolds(idx, 5)
  for(i in array(1:5)){
    x.test <- x[fld[[i]],]
    y.test <- y[fld[[i]],]
    x.train <- x[-fld[[i]],]
    y.train <- y[-fld[[i]],]
    fit <- iregnet(x = x.train, y = y.train)
    pred <- predict(fit, x.test)[,100]
    pred.val[fld[[i]]] <- pred
  }
  return(pred.val)
  
}
```


Run this function and test its error rate!
```{r,error=FALSE, warning= FALSE}
pred.ireg <- iregnet.CV(X,Y.ireg )
error_rate.ireg <- test_error(pred.ireg, Y.iter)
cat("The error rate for iregnet.CV:",error_rate.ireg)
```

The error rate of these two function seems to be almost low. 

Due to the randomness of these two test, simply compare a single pair of result is not accurate. To better perform the comparision, we run each test 20 times and use a T test to compare the result. 


```{r, error=FALSE, warning= FALSE}
error_list.iter <- c()
error_list.ireg <- c()
for(seed in range(1:20)){
  set.seed(seed)
  cat(seed)
  fit.iter <- IntervalRegressionCV(X,Y.iter, n.folds = 5L)
  perd.iter <- fit.iter$predict()
  error_list.iter <- c(error_list.iter,test_error(perd.iter, Y.iter))
  pred.ireg <- iregnet.CV(X,Y.ireg, seed = seed)
  error_list.ireg <- c(error_list.ireg, test_error(pred.ireg, Y.iter))
}
plt.dat <- data.frame(func=as.factor(c(rep('IntervalRegressionCV',20),rep('iregnet',20))),
                      error.rate = c(error_list.iter,error_list.ireg)
                      )

p <- ggplot(plt.dat, aes(x = func, y = error.rate))+
  geom_boxplot()
p
```




```{r,error=FALSE, warning= FALSE}
t.test(error_list.ireg, error_list.iter)
```



P Value < 0.05, we can say that there is no difference between the performances of these two function.

